{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparmeters\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "momentum=0.5\n",
    "epoch=10\n",
    "# Other constants\n",
    "input_size = 28*28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделите данные на 3 выборке (обучающая, валидационная, тестовая)\n",
    "\n",
    "dataset = MNIST(root='data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "test_ds = MNIST(root='data/', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2)\n",
    "test_loader = DataLoader(test_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistModel(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Выберите метрику для оценки классификатора\n",
    "# Постройте классификатор цифр. Используйте валидационную выборку для выбора модели/оптимизации гиперпараметров. \n",
    "\n",
    "\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 128)\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.linear3 = nn.Linear(64, num_classes)\n",
    "\n",
    "       \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        xb = F.relu(self.linear1(xb))\n",
    "        xb = F.relu(self.linear2(xb))\n",
    "        xb = self.linear3(xb)\n",
    "        xb = F.log_softmax(xb,dim=1)\n",
    "        return xb\n",
    "   \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  \n",
    "        loss = F.cross_entropy(out, labels) # Расчёт потерь\n",
    "        return loss\n",
    "   \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                    \n",
    "        loss = F.cross_entropy(out, labels)   # Расчёт потерь\n",
    "        acc = accuracy(out, labels)           # Расчёт точности\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n",
    "    \n",
    "    def validation_step_train(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                    \n",
    "        loss = F.cross_entropy(out, labels)   # Расчёт потерь\n",
    "        acc = accuracy(out, labels)           # Расчёт точности\n",
    "        return {'train_loss': loss.detach(), 'train_acc': acc.detach()}\n",
    "       \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Средняя потеря\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Средняя точность\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def validation_epoch_end_train(self, outputs):\n",
    "        batch_losses = [x['train_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Средняя потеря\n",
    "        batch_accs = [x['train_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Средняя точность\n",
    "        return {'train_loss': epoch_loss.item(), 'train_acc': epoch_acc.item()}\n",
    "   \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "    def epoch_end_train(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}\".format(epoch, result['train_loss'], result['train_acc']))\n",
    "   \n",
    "\n",
    "model = MnistModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def evaluate_train(model, train_loader):\n",
    "    outputs = [model.validation_step_train(batch) for batch in train_loader]\n",
    "    return model.validation_epoch_end_train(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    history_train = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), lr, momentum=momentum)\n",
    "    for epoch in range(epochs):\n",
    "        # Обучение\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Валидация\n",
    "        result = evaluate(model, val_loader)\n",
    "        result_train = evaluate_train(model, train_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        model.epoch_end_train(epoch, result_train)\n",
    "        history.append(result)\n",
    "        history_train.append(result_train)\n",
    "    return history, history_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3029403686523438, 'val_acc': 0.0927734375}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.0838, val_acc: 0.7528\n",
      "Epoch [0], train_loss: 1.0711, train_acc: 0.7639\n",
      "Epoch [1], val_loss: 0.4972, val_acc: 0.8688\n",
      "Epoch [1], train_loss: 0.4842, train_acc: 0.8695\n",
      "Epoch [2], val_loss: 0.4054, val_acc: 0.8863\n",
      "Epoch [2], train_loss: 0.3889, train_acc: 0.8925\n",
      "Epoch [3], val_loss: 0.3693, val_acc: 0.8964\n",
      "Epoch [3], train_loss: 0.3485, train_acc: 0.9006\n",
      "Epoch [4], val_loss: 0.3471, val_acc: 0.9018\n",
      "Epoch [4], train_loss: 0.3273, train_acc: 0.9066\n",
      "Epoch [5], val_loss: 0.3230, val_acc: 0.9083\n",
      "Epoch [5], train_loss: 0.3006, train_acc: 0.9140\n",
      "Epoch [6], val_loss: 0.3054, val_acc: 0.9126\n",
      "Epoch [6], train_loss: 0.2830, train_acc: 0.9193\n"
     ]
    }
   ],
   "source": [
    "history, history_train = fit(epoch, learning_rate, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loss = [r['val_loss'] for r in history]\n",
    "loss = [r['train_loss'] for r in history_train]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(val_loss, '-x', c='r')\n",
    "plt.plot(loss, '-x', c='b')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Val.loss (red) vs Train loss (blue)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(model, test_loader)\n",
    "result #проверка на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_ds[0] #Пример успешного предсказания\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На валидационной выборке отобразите несколько примеров, на которых классификатор не справляется с задачей.\n",
    "\n",
    "imcount = 0\n",
    "\n",
    "for i in range(len(val_ds)):\n",
    "    img, label = val_ds[i]\n",
    "    prediction = predict_image(img, model)\n",
    "    if label != prediction:\n",
    "        if imcount<6:\n",
    "            plt.subplot(2,3,imcount+1)\n",
    "            plt.tight_layout()\n",
    "            imcount+=1;\n",
    "            plt.imshow(img[0], cmap='gray')\n",
    "            plt.title(f'Label: {label}, Predicted: {predict_image(img, model)}')\n",
    "        else:\n",
    "            break\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Выведите classification_report на тестовой выборке.\n",
    "\n",
    "cls_data = [[],[]]\n",
    "\n",
    "for i in range(len(test_ds)):\n",
    "    img, label = test_ds[i]\n",
    "    prediction = predict_image(img, model)\n",
    "    cls_data[0].append(label)\n",
    "    cls_data[1].append(prediction)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(cls_data[0], cls_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите самые часто перепутываемые пары цифр.(Проверял на всём датасете)\n",
    "\n",
    "n = 10\n",
    "m = 10\n",
    "\n",
    "cls_err = [[0] * m for i in range(n)]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    img, label = dataset[i]\n",
    "    prediction = predict_image(img, model)\n",
    "    if label != prediction:\n",
    "        cls_err[label][prediction]+=1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cls_err_np = np.array(cls_err)\n",
    "\n",
    "def mx_elem(a):\n",
    "    max_elem = a[0][0]\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[i] )):\n",
    "             if a[i][j] > max_elem:\n",
    "                max_elem =  a[i][j]\n",
    "\n",
    "    list_index_max =[ (i,j) for i in range(len(a))  for j in range(len(a[i])) if a[i][j]  == max_elem]\n",
    "    line, column = list_index_max[0]\n",
    "    return [line,column,max_elem]\n",
    "\n",
    "def mx_pairs(a):\n",
    "    a = a + np.transpose(a)\n",
    "    a = np.triu(a)\n",
    "    for i in range(5):\n",
    "        elem = mx_elem(a)\n",
    "        print('Чаще всего путают: ')\n",
    "        print(f'Цифры {elem[0]} и {elem[1]}: {elem[2]} количество раз')\n",
    "        a[elem[0]][elem[1]]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_pairs(cls_err_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
